{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from fnmatch import fnmatch\n",
    "import pandas as pd\n",
    "import re\n",
    "import tqdm\n",
    "import plotnine as p9\n",
    "import patchworklib as pw\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_from_path(path: str):\n",
    "    params_name_pattern = \"([a-zA-Z]*)-\"\n",
    "    param_names = [path[m.start():m.end()-1] for m in re.finditer(params_name_pattern, path)]\n",
    "    dict = {}\n",
    "    for param in param_names:\n",
    "        dict[param] = 0\n",
    "    return dict\n",
    "\n",
    "def construct_regex_string(path: str, names: dict):\n",
    "    res: str = \"\"\n",
    "    last_key = list(names.keys())[-1]\n",
    "    for key in list(names.keys()):\n",
    "        res = res + key + \"-([0-9.]*)\"\n",
    "        if key != last_key:\n",
    "            res = res + '_'\n",
    "    return res\n",
    "\n",
    "def extract_parms(filepath: str):\n",
    "    param_st = filepath.split('/')[-2]\n",
    "    params = dict_from_path(param_st)\n",
    "    regex_str = construct_regex_string(param_st, params)\n",
    "    result = re.search(regex_str, param_st)\n",
    "    keys = list(params.keys())\n",
    "    for x, key in enumerate(keys):\n",
    "        params[key] = float(result.group(x+1))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getcwd(),'output')\n",
    "pattern = \"logger_6_Ve.csv\"\n",
    "file_paths = []\n",
    "dfsV = []\n",
    "\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "        if fnmatch(name, pattern):\n",
    "            file_path = os.path.join(path, name)\n",
    "            file_paths.append(file_path)\n",
    "            df = pd.read_csv(file_path, sep='\\t')\n",
    "            params = extract_parms(file_path)\n",
    "            add = True\n",
    "            for key in list(params.keys()):\n",
    "                if round(params[key],1) != 999.0 and round(params[key],1) % 0.2 != 0:\n",
    "                    add = False\n",
    "                    continue\n",
    "                df[key] = round(params[key],1)\n",
    "            if add == True:\n",
    "                dfsV.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simV = pd.concat(dfsV)\n",
    "simV = simV[simV[\"10\"] != 10]\n",
    "simV['time'] = np.tile(np.repeat(range(0,51),10),int(len(simV.index)/510))\n",
    "simV['sum_V_x'] = simV.iloc[:, 1:11].sum(axis=1)\n",
    "simV = simV.drop(columns=[str(x) for x in range(0,11)])\n",
    "simV = simV.groupby(list(simV.columns[:-1])).agg({'sum_V_x': 'sum'}).reset_index()\n",
    "simV = simV.groupby(['DV','bcf','pi','cv','time']).agg({'sum_V_x':['mean','std']})\n",
    "simV.columns = [\"_\".join(x) for x in simV.columns.ravel()]\n",
    "simV = simV.rename({'sum_V_x_mean':'mean','sum_V_x_std':'std'}, axis='columns')\n",
    "simV['cv_cat'] = simV['cv'].astype(\"category\")\n",
    "simV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getcwd(),'output')\n",
    "pattern = \"logger_2.csv\"\n",
    "file_paths = []\n",
    "dfs = []\n",
    "\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "        if fnmatch(name, pattern):\n",
    "            file_path = os.path.join(path, name)\n",
    "            file_paths.append(file_path)\n",
    "            df = pd.read_csv(file_path, sep='\\t')\n",
    "            params = extract_parms(file_path)\n",
    "            add = True\n",
    "            for key in list(params.keys()):\n",
    "                if round(params[key],1) != 999.0 and round(params[key],1) % 0.2 != 0:\n",
    "                    add = False\n",
    "                    continue\n",
    "                df[key] = round(params[key],1)\n",
    "            if add == True:\n",
    "                dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = pd.concat(dfs)\n",
    "sim = sim[sim['time'] >= 10]\n",
    "simI = sim.groupby(['DV','bcf','pi','cv','time']).agg({'celltype.infected.size':['mean','std']})\n",
    "simI.columns = [\"_\".join(x) for x in simI.columns.ravel()]\n",
    "simI = simI.rename({'celltype.infected.size_mean':'mean','celltype.infected.size_std':'std'}, axis='columns')\n",
    "simI = simI.reset_index()\n",
    "#simI = simI.query('bcf > 0.8 and pi > 0.8 and cv > 0.8')\n",
    "simI['cv_cat'] = simI['cv'].astype(\"category\")\n",
    "simI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ode = pd.read_csv('simulations_ode.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "156dc4edc9195e2fda522b950e81ebd74b0250a6ebba1d0103c9c544b1b38cc6"
  },
  "kernelspec": {
   "display_name": "cell_free_venv",
   "language": "python",
   "name": "cell_free_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
